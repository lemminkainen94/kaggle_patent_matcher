{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6c50791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b73c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "LR = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39633267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>context_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>furniture; domestic articles or appliances; co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score  \\\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n",
       "\n",
       "                                        context_text  \n",
       "0  furniture; domestic articles or appliances; co...  \n",
       "1  furniture; domestic articles or appliances; co...  \n",
       "2  furniture; domestic articles or appliances; co...  \n",
       "3  furniture; domestic articles or appliances; co...  \n",
       "4  furniture; domestic articles or appliances; co...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebca883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36473, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e8de6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_input(row, text):\n",
    "    return f'{row.anchor} [SEP] {row.target} [SEP] {row.context_text if text else row.context}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c4f2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        abatement [SEP] abatement of pollution [SEP] A47\n",
       "1                abatement [SEP] act of abating [SEP] A47\n",
       "2               abatement [SEP] active catalyst [SEP] A47\n",
       "3           abatement [SEP] eliminating process [SEP] A47\n",
       "4                 abatement [SEP] forest region [SEP] A47\n",
       "                               ...                       \n",
       "36468         wood article [SEP] wooden article [SEP] B44\n",
       "36469             wood article [SEP] wooden box [SEP] B44\n",
       "36470          wood article [SEP] wooden handle [SEP] B44\n",
       "36471        wood article [SEP] wooden material [SEP] B44\n",
       "36472       wood article [SEP] wooden substrate [SEP] B44\n",
       "Length: 36473, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(get_transformer_input, text=False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "543fce13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        abatement [SEP] abatement of pollution [SEP] f...\n",
       "1        abatement [SEP] act of abating [SEP] furniture...\n",
       "2        abatement [SEP] active catalyst [SEP] furnitur...\n",
       "3        abatement [SEP] eliminating process [SEP] furn...\n",
       "4        abatement [SEP] forest region [SEP] furniture;...\n",
       "                               ...                        \n",
       "36468    wood article [SEP] wooden article [SEP] decora...\n",
       "36469    wood article [SEP] wooden box [SEP] decorative...\n",
       "36470    wood article [SEP] wooden handle [SEP] decorat...\n",
       "36471    wood article [SEP] wooden material [SEP] decor...\n",
       "36472    wood article [SEP] wooden substrate [SEP] deco...\n",
       "Length: 36473, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(get_transformer_input, text=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84884baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatentDataset(Dataset):\n",
    "    def __init__(self, texts, scores, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.scores = scores\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)  \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        score = self.scores[idx] if self.scores is not None else None\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=False,\n",
    "            max_length=self.max_len,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=\"only_first\"\n",
    "        )\n",
    "        \n",
    "        item = {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        }\n",
    "\n",
    "        if score:\n",
    "            item[\"scores\"] = torch.tensor(score, dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b68be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, text=False):\n",
    "    ds = PatentDataset(\n",
    "        texts=df.apply(get_transformer_input, text=True, axis=1).to_numpy(),\n",
    "        scores=df.score.to_numpy() if \"score\" in df.columns else None,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN,\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfcfa708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3fe28c6de34d0aaa871ab5da99aa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wojtek\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0445524077e34cb290f7015d0acb86a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145e73fd503c48aea1d3fb879990f5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\wojtek\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e17638d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = create_data_loader(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfda6e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['compression loss [SEP] loss of smell [SEP] machines or engines in general; engine plants in general; steam engines', 'connect to common conductor [SEP] self adjusting load responsive brake [SEP] hoisting; lifting; hauling', 'normal base [SEP] base system [SEP] printing; lining machines; typewriters; stamps', 'oxygen value [SEP] gas level [SEP] combustion engines; hot-gas or combustion-product engine plants', 'speed control means [SEP] network control [SEP] controlling; regulating', 'walnut oil [SEP] black walnut oil [SEP] medical or veterinary science; hygiene', 'tunneling capacitor [SEP] drain region [SEP] information storage', 'single pumping chamber [SEP] single pumping chamber outlet port [SEP] positive - displacement machines for liquids; pumps for liquids or elastic fluids', 'alumino silicates [SEP] oxides which zeolites [SEP] photography; cinematography; analogous techniques using waves other than optical waves; electrography; holography', 'filled interior [SEP] cavity [SEP] medical or veterinary science; hygiene', 'antigen composition [SEP] portion antigen [SEP] medical or veterinary science; hygiene', 'implement with plurality [SEP] perform with plurality tools [SEP] agriculture; forestry; animal husbandry; hunting; trapping; fishing', 'biocytin [SEP] blood stain [SEP] organic chemistry', 'produce by pump [SEP] produced by pump [SEP] opening, closing {or cleaning} bottles, jars or similar containers; liquid handling', 'flexible glass substrate [SEP] optically clear adhesive [SEP] layered products', 'oxygen carrier [SEP] solution [SEP] physical or chemical processes or apparatus in general', 'leveller [SEP] blood level detector [SEP] combustion engines; hot-gas or combustion-product engine plants', 'projection method [SEP] irradiating apparatus [SEP] machine tools; metal-working not otherwise provided for', 'demodulator [SEP] power circuit [SEP] generation; conversion or distribution of electric power', 'annular neck [SEP] neck glands [SEP] working of plastics; working of substances in a plastic state in general', 'sheet supply roller [SEP] cookie sheet surface [SEP] conveying; packing; storing; handling thin or filamentary material', 'central nucleus [SEP] nucleus of an atom [SEP] dyes; paints; polishes; natural resins; adhesives; compositions not otherwise provided for; applications of materials not otherwise provided for', 'based method [SEP] program [SEP] electric communication technique', 'ingress buffer [SEP] buffer action [SEP] electric communication technique', 'ply tire [SEP] plywood [SEP] working of plastics; working of substances in a plastic state in general', 'ply tire [SEP] radial ply tire [SEP] working of plastics; working of substances in a plastic state in general', 'include displacement [SEP] include displacement [SEP] machine tools; metal-working not otherwise provided for', 'substantially axial [SEP] generally circumferential [SEP] machines or engines in general; engine plants in general; steam engines', 'engage clamp [SEP] connecting sockets [SEP] basic electric elements', 'conduct cables [SEP] conduct cables [SEP] engineering elements and units; general measures for producing and maintaining effective functioning of machines or installations; thermal insulation in general', 'solder member [SEP] new member [SEP] basic electric elements', 'acoustooptic modulator [SEP] isolator [SEP] basic electric elements'], 'input_ids': tensor([[    1,  9787,  1265,  ...,     0,     0,     0],\n",
      "        [    1,  2474,   264,  ...,     0,     0,     0],\n",
      "        [    1,  1697,  1436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  3360,  9678,  ...,     0,     0,     0],\n",
      "        [    1, 28051,  1034,  ...,     0,     0,     0],\n",
      "        [    1,   266, 71206,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojtek\\AppData\\Local\\Temp\\ipykernel_12588\\16416872.py:33: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"scores\"] = torch.tensor(score, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "for b in train_dl:\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3693a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
